# General Configuration (Cloud Run Deployment)
# This file contains production deployment configuration
# For local development, use .env.local instead

# Database connection (Cloud SQL via Unix socket)
DATABASE_URL=postgresql+asyncpg://rag_user:your-password@/rag_db?host=/cloudsql/your-project:us-central1:rag-postgres

# GCP configuration
GCP_PROJECT_ID=your-gcp-project-id
GCP_REGION=us-central1
GCS_BUCKET=your-project-id-rag-documents
CLOUD_SQL_CONNECTION_NAME=your-project-id:us-central1:rag-postgres
SERVICE_ACCOUNT_EMAIL=rag-service@your-project-id.iam.gserviceaccount.com

# Vertex AI
VERTEX_AI_LOCATION=us-central1
EMBEDDING_MODEL=text-embedding-005
EMBEDDING_DIMENSION=768  # text-embedding-005 max dimension

# FastAPI
PORT=8080

# Logging (set to DEBUG for detailed logs during development)
LOG_LEVEL=INFO

# GCS Connection Pool (controls concurrent upload/download operations)
# Must match urllib3 connection pool size (default: 10)
GCS_CONNECTION_POOL_SIZE=10

# Authentication & Authorization (Production: use workload identity, no user lists)
# For local dev: populate ALLOWED_USERS, JWKS_URL, ISSUER, AUDIENCE in .env.local
# ALLOWED_USERS=user1@example.com,user2@example.com
# TRUSTED_SERVICE_ACCOUNTS=backend-sa@project.iam.gserviceaccount.com
# JWKS_URL=https://www.googleapis.com/oauth2/v3/certs
# ISSUER=https://accounts.google.com
# AUDIENCE=your-oauth-client-id

# Reranking (optional - improves search relevance at cost of latency)
# Enable reranking for better search quality (multi-stage retrieval)
RERANKER_ENABLED=false

# Reranker type: "gemini" (LLM-based, recommended) | "local" (cross-encoder) | "cohere" (API)
# Gemini: Best quality, ~500ms/query, uses Google Cloud AI
# Local: Fast (~100ms), runs in Cloud Run, no API costs, offline-capable
# Cohere: Commercial API, high quality, paid
RERANKER_TYPE=gemini

# Reranker model (type-specific):
# Gemini models (RERANKER_TYPE=gemini):
#   - gemini-2.5-flash-lite (RECOMMENDED: cheap, reliable, tested)
#   - gemini-2.5-flash (more expensive, 10% JSON failures in extraction)
#   - gemini-2.0-flash-exp (experimental, may change)
# Local models (RERANKER_TYPE=local):
#   - cross-encoder/ms-marco-MiniLM-L-12-v2 (120MB, fast, good)
#   - BAAI/bge-reranker-base (1.1GB, better quality)
# Cohere models (RERANKER_TYPE=cohere):
#   - rerank-english-v3.0 (best for English)
#   - rerank-multilingual-v3.0 (100+ languages)
RERANKER_MODEL=gemini-2.5-flash-lite

# LLM Extraction (for summary + keywords generation during upload)
# Used for BM25 hybrid search metadata extraction
# Recommended: gemini-2.5-flash-lite (cheapest, $0.10/1M input + $0.40/1M output)
# Cost: ~$0.000225 per document (~$2.25 per 10K docs, 4.2x cheaper than flash)
# Alternative: gemini-2.5-flash ($9.35 per 10K docs, better quality for complex docs)
LLM_EXTRACTION_MODEL=gemini-2.5-flash-lite

# Google Cloud configuration (required for RERANKER_TYPE=gemini)
# Uses GCP_PROJECT_ID and GCP_REGION from above
# GOOGLE_CLOUD_LOCATION defaults to GCP_REGION

# Cohere API key (only needed if RERANKER_TYPE=cohere)
# COHERE_API_KEY=your-cohere-api-key
