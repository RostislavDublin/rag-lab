# General Configuration (Cloud Run Deployment)
# This file contains production deployment configuration
# For local development, use .env.local instead

# Database connection (Cloud SQL via Unix socket)
DATABASE_URL=postgresql+asyncpg://rag_user:your-password@/rag_db?host=/cloudsql/your-project:us-central1:rag-postgres

# GCP configuration
GCP_PROJECT_ID=your-gcp-project-id
GCP_REGION=us-central1
GCS_BUCKET=your-project-id-rag-documents
CLOUD_SQL_CONNECTION_NAME=your-project-id:us-central1:rag-postgres
SERVICE_ACCOUNT_EMAIL=rag-service@your-project-id.iam.gserviceaccount.com

# Vertex AI
VERTEX_AI_LOCATION=us-central1
EMBEDDING_MODEL=text-embedding-005
EMBEDDING_DIMENSION=1408

# Reranking (optional - improves search relevance at cost of latency)
# Enable reranking for better search quality (multi-stage retrieval)
RERANKER_ENABLED=false

# Reranker type: "gemini" (LLM-based, recommended) | "local" (cross-encoder) | "cohere" (API)
# Gemini: Best quality, ~500ms/query, uses Google Cloud AI
# Local: Fast (~100ms), runs in Cloud Run, no API costs, offline-capable
# Cohere: Commercial API, high quality, paid
RERANKER_TYPE=gemini

# Reranker model (type-specific):
# Gemini models (RERANKER_TYPE=gemini, default):
#   - gemini-2.5-flash (RECOMMENDED: stable, production-ready, Dec 2025)
#   - gemini-2.0-flash-exp (experimental, may change)
#   - gemini-1.5-flash (deprecated, use 2.5)
# Local models (RERANKER_TYPE=local):
#   - cross-encoder/ms-marco-MiniLM-L-12-v2 (120MB, fast, good)
#   - BAAI/bge-reranker-base (1.1GB, better quality)
#   - BAAI/bge-reranker-large (1.4GB, best quality)
# Cohere models (RERANKER_TYPE=cohere):
#   - rerank-english-v3.0 (best for English)
#   - rerank-multilingual-v3.0 (100+ languages)
RERANKER_MODEL=gemini-2.5-flash

# LLM Extraction (for summary + keywords generation during upload)
# Used for BM25 hybrid search metadata extraction
# Recommended: gemini-2.5-flash-lite (cheapest, $0.10/1M input + $0.40/1M output)
# Cost: ~$0.000225 per document (~$2.25 per 10K docs, 4.2x cheaper than flash)
# Alternative: gemini-2.5-flash ($9.35 per 10K docs, better quality for complex docs)
LLM_EXTRACTION_MODEL=gemini-2.5-flash-lite

# Google Cloud configuration (required for RERANKER_TYPE=gemini)
# Uses GCP_PROJECT_ID and GCP_REGION from above
# GOOGLE_CLOUD_LOCATION defaults to GCP_REGION

# Cohere API key (only needed if RERANKER_TYPE=cohere)
# COHERE_API_KEY=your-cohere-api-key
