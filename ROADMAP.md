# RAG Lab - Product Roadmap

**Last Updated:** December 19, 2025  
**Current Version:** 0.2.1  
**Status:** Production-ready with hybrid search Phase 2 complete. Models unified to gemini-2.5-flash-lite (extraction + reranking). All env vars now required (no defaults). BigQuery billing analytics ready. All 194 tests passing. **Next: Phase 3 (BM25 query integration) or Metadata Filtering.**

---

## üéØ Current State Assessment

### ‚úÖ Implemented (Production-Ready)

**Core RAG Capabilities:**
- ‚úÖ Multi-format document ingestion (17 formats: PDF, TXT, MD, JSON, XML, CSV, YAML, HTML, logs, code)
- ‚úÖ Smart text extraction (PDF‚ÜíMarkdown, JSON/XML‚ÜíYAML for LLM optimization)
- ‚úÖ Vector embeddings (Vertex AI text-embedding-005, 768 dimensions)
- ‚úÖ Semantic search (PostgreSQL + pgvector, cosine similarity)
- ‚úÖ Similarity threshold filtering (min_similarity parameter to filter irrelevant results)
- ‚úÖ SHA256 deduplication (prevents duplicate document uploads)
- ‚úÖ Hybrid storage architecture (PostgreSQL for embeddings, GCS for documents - 8.5x cost savings)
- ‚úÖ Metadata filtering (MongoDB Query Language with 12 operators: $and, $or, $not, $eq, $ne, $gt, $gte, $lt, $lte, $in, $nin, $all, $exists)
- ‚úÖ **Hybrid Search Phase 2 (Upload Integration):** BM25 index generation, LLM summary/keywords extraction, PostgreSQL schema migration (summary TEXT, keywords TEXT[], token_count INTEGER + GIN index), GCS bm25_doc_index.json storage, Snowball stemming with stopwords filtering

**Infrastructure & Operations:**
- ‚úÖ Cloud Run deployment with auto-scaling
- ‚úÖ Multi-cloud portable (works on GCP, AWS, Azure with PostgreSQL)
- ‚úÖ Cost-optimized ($7-12/month for 10k documents)
- ‚úÖ Comprehensive testing (194 tests: 134 unit, 23 integration, 37 e2e - all passing)
- ‚úÖ Local development workflow with hot reload
- ‚úÖ File validation (3-tier: strict for PDF, structured for JSON/XML, lenient for text)
- ‚úÖ **LLM Models:** Unified to `gemini-2.5-flash-lite` for extraction and reranking (100% success rate, 30x faster than gemini-2.5-flash, cheaper)
- ‚úÖ **Configuration:** All env vars required (no defaults in code), explicit .env.local setup
- ‚úÖ **BigQuery Billing Analytics:** OAuth-based query tool (scripts/query_billing.py), dataset: myai-475419.billing_export, waiting for data (24-48hrs)

---

## ‚ùå Missing Features (Industry Standard Gaps)

**Note:** Metadata Filtering and Reranking are now ‚úÖ IMPLEMENTED (Dec 2025).

### 1. **Hybrid Search (BM25 + Vector)** ‚úÖ Phase 2 COMPLETE | ‚è≥ Phase 3 NEXT
**Priority:** P0 (Current Sprint - Week of Dec 16-22, 2025)  
**Effort:** 17-26 hours total (5 phases) | **Phase 2: 8 hours DONE** | **Phase 3: 4-6 hours remaining**  
**Impact:** HIGH - Better retrieval quality for keyword + semantic queries  
**Blueprint:** [docs/hybrid-search.md](docs/hybrid-search.md) ‚Üê **Detailed design document**

**Current Status:** ‚úÖ Phase 2 Complete (Upload Integration) ‚Üí üöß Phase 3 Next (Query Integration)

**Phase 2 Completed (December 17-18, 2025):**
- ‚úÖ Database schema migration: summary TEXT, keywords TEXT[], token_count INTEGER
- ‚úÖ GIN index on keywords array for fast filtering
- ‚úÖ BM25 tokenizer with Snowball stemming (nltk) + stopwords filtering (34 words)
- ‚úÖ BM25 index builder: document-level term frequency aggregation
- ‚úÖ **LLM extraction:** gemini-2.5-flash-lite (4.2x cheaper, 100% reliable) ~$0.000225/doc
- ‚úÖ **Retry logic:** 5 attempts with exponential backoff (1s, 2s, 4s, 8s, 16s)
- ‚úÖ **Model stability:** Flash-lite: 100% success vs Flash: 90% (JSON parse errors)
- ‚úÖ GCS upload: bm25_doc_index.json (1-5KB per document)
- ‚úÖ Upload endpoint integration: full pipeline working
- ‚úÖ API endpoints updated: /v1/documents returns summary/keywords/token_count
- ‚úÖ Log retention fix: keeps last 5 files (was accumulating 50+)
- ‚úÖ **All tests passing:** 194 passed (134 unit, 23 integration, 37 e2e)

**Model Selection (Dec 18, 2025):**
- **Extraction:** gemini-2.5-flash-lite ($2.25/10K docs) - 100% reliable, complete JSON every time
- **Reranking:** gemini-2.5-flash (stable for search, NOT for extraction due to 10% JSON errors)
- **Environment vars:** EMBEDDING_MODEL, RERANKER_MODEL, LLM_EXTRACTION_MODEL (independent optimization)

**Problem:**  
Pure vector search struggles with:
- Exact product names ("iPhone 16 Pro Max")
- Codes/IDs ("INV-2025-001234")
- Proper nouns ("John Smith", "Microsoft Azure")
- Technical terms that must match exactly ("Kubernetes", "PostgreSQL")

**Solution:**  
Hybrid search combining:
- **Vector search** (chunk-level, semantic similarity)
- **Simplified BM25** (document-level, keyword matching, no global IDF)
- **RRF fusion** (Reciprocal Rank Fusion to combine rankings)
- **LLM keywords** (compensate missing IDF with semantic importance)

**Architecture:**
```
Upload Flow:
  1. Extract text ‚Üí chunk ‚Üí generate embeddings
  2. LLM generates summary (2-3 sentences) + keywords (10-15 terms)
  3. Save to PostgreSQL: summary, keywords, token_count
  4. Compute term_frequencies for full document
  5. Save to GCS: bm25_doc_index.json (only term_frequencies!)

Search Flow:
  1. Vector search (top-100 chunks, PostgreSQL)
  2. Fetch bm25_doc_index.json from GCS (parallel batch)
  3. BM25 scoring with keyword boosting (1.5x for LLM keywords)
  4. RRF fusion: score = Œ£ 1/(60 + rank_i)
  5. Optional cross-encoder reranking (existing)
```

**Benefits:**
- ‚úÖ Best of both worlds (semantic + keyword)
- ‚úÖ No distributed state (Simplified BM25, no global IDF)
- ‚úÖ Summary in search results (better UX)
- ‚úÖ Keyword filtering ready (`WHERE 'Kubernetes' = ANY(keywords)`)
- ‚úÖ Existing filter_parser compatible
- ‚úÖ No external dependencies

---

### 2. **Multi-Tenancy / User Isolation** üî¥ CRITICAL
**Priority:** P0 (MUST HAVE - part of Metadata Filtering)  
**Effort:** 2 hours (included in metadata filtering)  
**Impact:** CRITICAL - Security requirement for SaaS

**Implementation:**
- Store `user_id` in metadata during upload
- Filter by `user_id` in all queries
- Row-level security (RLS) in PostgreSQL (optional hardening)

**Security Model:**
```python
# Upload
metadata = {
    "user_id": get_current_user_id(),
    "org_id": get_current_org_id(),
    "visibility": "private"  # or "shared", "public"
}

# Query (automatic injection)
filters = {
    "user_id": current_user.id,
    "visibility": {"$in": ["private", "shared"]}  # Supports user's docs + shared docs
}
```

---

### 3. **Schema Migration System** üü° HIGH
**Priority:** P1 (Next Quarter - Infrastructure Improvement)  
**Effort:** 12-16 hours  
**Impact:** HIGH - Production operations requirement

**Problem:**  
Currently using `CREATE TABLE IF NOT EXISTS` + `ALTER TABLE ADD COLUMN IF NOT EXISTS` in application code (`init_schema()`).
Issues:
- Schema changes mixed with application runtime
- No version tracking
- No rollback capability
- Difficult to test migrations
- Cannot verify schema state before deployment

**Solution:**  
Implement versioned migration system:

**PostgreSQL Migrations:**
- **Tool:** Alembic (industry standard for async Python + PostgreSQL)
- **Versions:** Track in `alembic_version` table
- **Migrations:** `deployment/migrations/versions/001_initial.py`, `002_hybrid_search.py`
- **Commands:** `alembic upgrade head`, `alembic downgrade -1`

**GCS Schema Versioning:**
- **Metadata:** `gs://bucket/.schema_version.json` ‚Üí `{"version": 2, "updated_at": "2025-12-17"}`
- **Migrations:** `deployment/migrations/gcs/001_initial_structure.py`, `002_add_bm25_index.py`
- **Runner:** Custom script checks version, applies needed migrations

**Migration Workflow:**
```bash
# 1. Deploy infrastructure (once)
./deployment/setup-infrastructure.sh

# 2. Run migrations (separate step, before app deploy)
alembic upgrade head                    # PostgreSQL
python deployment/migrate_gcs.py        # GCS schema

# 3. Deploy application (uses ready schema, no init_schema())
./deployment/deploy-cloudrun.sh
```

**Benefits:**
- ‚úÖ Separation of concerns (provisioning vs runtime)
- ‚úÖ Version tracking and history
- ‚úÖ Rollback capability
- ‚úÖ Testable migrations (can test on staging)
- ‚úÖ Schema drift detection
- ‚úÖ Team collaboration (clear migration history in git)

---

### 4. **Document Updates / Versioning** üü¢ MEDIUM
**Priority:** P3 (Nice to Have - Backlog)  
**Effort:** 8 hours  
**Impact:** MEDIUM - Needed for evolving documents

**Problem:**  
Current implementation: documents are immutable. No way to update content.

**Options:**

**A) Soft Delete + New Version (Recommended):**
```sql
ALTER TABLE original_documents ADD COLUMN deleted_at TIMESTAMP;
ALTER TABLE original_documents ADD COLUMN replaced_by_uuid UUID;

-- Keep history for auditing
-- Queries filter WHERE deleted_at IS NULL
```

**B) Hard Replace:**
- Delete old document + chunks
- Upload new version
- Simpler but loses history

**C) Full Versioning:**
```sql
ALTER TABLE original_documents ADD COLUMN version_number INT DEFAULT 1;
ALTER TABLE original_documents ADD COLUMN parent_uuid UUID;

-- Query specific version
SELECT * WHERE doc_uuid = $uuid AND version_number = $version;

-- Query latest
SELECT * WHERE doc_uuid = $uuid ORDER BY version_number DESC LIMIT 1;
```

---

### 5. **Parent Document Retrieval** üü¢ MEDIUM
**Priority:** P3 (Nice to Have - Backlog)  
**Effort:** 10 hours  
**Impact:** MEDIUM - Better context for LLM generation

**Problem:**  
Small chunks (2000 chars) = high recall but lose context.  
Large chunks (10000 chars) = good context but poor recall.

**Solution:**  
Search with small chunks, return parent chunks:
```
Document
  ‚îú‚îÄ Parent Chunk 1 (10000 chars) ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ   ‚îú‚îÄ Child Chunk 1.1 (2000 chars) ‚îÇ Search these
  ‚îÇ   ‚îú‚îÄ Child Chunk 1.2 (2000 chars) ‚îÇ
  ‚îÇ   ‚îî‚îÄ Child Chunk 1.3 (2000 chars) ‚îÇ
  ‚îÇ                                    ‚îÇ
  ‚îî‚îÄ Parent Chunk 2 (10000 chars) ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îú‚îÄ Child Chunk 2.1
       ‚îî‚îÄ Child Chunk 2.2

Search Match: Child 1.2
Return: Parent 1 (full 10000 chars context)
```

**Schema:**
```sql
ALTER TABLE document_chunks ADD COLUMN parent_chunk_index INT;
-- child chunks reference parent chunk in same document
```

---

### 6. **Async Processing** üü¢ LOW
**Priority:** P4 (Nice to Have - Backlog)  
**Effort:** 10 hours  
**Impact:** LOW - UX improvement, not critical

**Problem:**  
Large PDF uploads block HTTP request for 30+ seconds.

**Solution:**  
Background job processing:
```
POST /v1/documents/upload
  ‚Üì
202 Accepted
{
  "job_id": "uuid",
  "status": "processing"
}

GET /v1/jobs/{job_id}
  ‚Üì
{
  "status": "completed",
  "doc_id": 123,
  "doc_uuid": "..."
}
```

**Tech Stack:**
- **Simple:** Cloud Tasks (serverless)
- **Advanced:** Celery + Redis (more features)

---

### 7. **Multi-Query / Query Decomposition** üü¢ LOW
**Priority:** P4 (Optimization - Backlog)  
**Effort:** 3 hours  
**Impact:** LOW - Edge case optimization

**Use Case:**  
Complex queries benefit from decomposition:
```
"Compare Q3 vs Q4 revenue growth trends"
  ‚Üì LLM decomposition
[
  "Q3 revenue data",
  "Q4 revenue data",
  "revenue growth analysis methodology"
]
  ‚Üì Search each
3 √ó vector_search()
  ‚Üì Merge & deduplicate
Final results
```

---

### 8. **Contextual Compression** üü¢ LOW
**Priority:** P4 (Optimization - Backlog)  
**Effort:** 4 hours  
**Impact:** LOW - Token optimization

**Problem:**  
Return full 2000-char chunks, but only 2-3 sentences are relevant.

**Solution:**  
LLM-based extraction:
```
Chunk: [2000 chars about product features]
Query: "pricing"
  ‚Üì LLM compression
Output: "Standard: $99/mo. Enterprise: $499/mo. Annual discount: 20%."
```

**Cost:** +1 LLM call per chunk (Gemini Flash = $0.0001/chunk)

---

### 9. **Query Analytics** üü¢ LOW
**Priority:** P4 (Observability - Backlog)  
**Effort:** 6 hours  
**Impact:** LOW - Product insights

**Features:**
- Query logging (text, timestamp, user_id, results_count)
- Popular queries tracking
- Zero-results queries (identify gaps)
- User feedback (thumbs up/down on results)
- A/B testing framework

**Schema:**
```sql
CREATE TABLE query_logs (
    id SERIAL PRIMARY KEY,
    query_text TEXT,
    user_id TEXT,
    filters JSONB,
    results_count INT,
    top_similarity FLOAT,
    latency_ms INT,
    timestamp TIMESTAMP,
    feedback INT  -- +1 (good), -1 (bad), NULL (no feedback)
);
```

---

## üìä Competitive Analysis

| Feature | RAG Lab | LangChain | LlamaIndex | Pinecone | Weaviate |
|---------|---------|-----------|------------|----------|----------|
| **Core Features** |
| Vector Search | ‚úÖ pgvector | ‚úÖ Multiple | ‚úÖ Multiple | ‚úÖ Native | ‚úÖ Native |
| Multi-format Ingestion | ‚úÖ 17 formats | ‚ö†Ô∏è Basic | ‚úÖ Good | ‚ùå Manual | ‚ö†Ô∏è Limited |
| Deduplication | ‚úÖ SHA256 | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| Smart Extraction | ‚úÖ PDF‚ÜíMD, JSON‚ÜíYAML | ‚ö†Ô∏è Basic | ‚úÖ Good | ‚ùå | ‚ùå |
| Similarity Threshold | ‚úÖ min_similarity | ‚ö†Ô∏è Manual | ‚úÖ | ‚úÖ | ‚úÖ |
| **Advanced Features** |
| Metadata Filtering | ‚úÖ MongoDB Query Language | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Hybrid Search (BM25+Vector) | ‚ùå **TODO** | ‚úÖ | ‚úÖ | ‚úÖ Sparse-Dense | ‚úÖ |
| Reranking | ‚ùå **TODO** | ‚úÖ Cohere | ‚úÖ Multiple | ‚úÖ | ‚úÖ |
| Multi-tenancy | ‚úÖ X-End-User-ID + TRUSTED_SAs | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Manual | ‚úÖ Namespaces | ‚úÖ Multi-tenant |
| Document Versioning | ‚ùå | ‚ö†Ô∏è Manual | ‚ùå | ‚ùå | ‚ö†Ô∏è Limited |
| **Infrastructure** |
| Cost Optimization | ‚úÖ Hybrid Storage | ‚ùå | ‚ùå | ‚ö†Ô∏è Expensive | ‚ö†Ô∏è Expensive |
| Multi-cloud Portable | ‚úÖ PostgreSQL | ‚úÖ | ‚úÖ | ‚ùå Cloud-only | ‚ùå Cloud-only |
| Auto-scaling | ‚úÖ Cloud Run | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Manual | ‚úÖ | ‚úÖ |
| Testing Coverage | ‚úÖ 74 tests | ‚ö†Ô∏è Varies | ‚ö†Ô∏è Varies | ‚ö†Ô∏è Proprietary | ‚ö†Ô∏è Proprietary |

**Legend:** ‚úÖ Full Support | ‚ö†Ô∏è Partial/Manual | ‚ùå Not Available

**Key Takeaways:**
- **Unique Strengths:** SHA256 deduplication, cost-optimized hybrid storage, multi-cloud portability, comprehensive testing, MongoDB-style filtering
- **Production Ready:** Metadata filtering, multi-tenancy, X-End-User-ID security (Phase 1 COMPLETE)
- **Competitive Gaps:** Reranking, hybrid search (P1 - should add)
- **Advanced Features:** Versioning, parent retrieval (P3 - nice to have)

---

## üéØ Recommended Roadmap

### Phase 1: Production Readiness (Next 2 Weeks)
**Goal:** Make RAG Lab production-ready for multi-tenant SaaS

1. **Metadata Filtering + Multi-Tenancy** ‚úÖ COMPLETED (Dec 13, 2025)
   - ‚úÖ Add JSONB metadata column with GIN index
   - ‚úÖ Implement filters parameter in query API (MongoDB Query Language)
   - ‚úÖ Add user_id to upload metadata
   - ‚úÖ Update all queries to filter by metadata
   - ‚úÖ Write tests for multi-tenant isolation
   
2. **Security: X-End-User-ID Access Control** ‚úÖ COMPLETED (Dec 15, 2025)
   - ‚úÖ Added `TRUSTED_SERVICE_ACCOUNTS` config parameter
   - ‚úÖ JWT validation: only whitelisted service accounts can set X-End-User-ID
   - ‚úÖ Regular users: X-End-User-ID ignored (403 Forbidden if attempted)
   - ‚úÖ Unit tests: 4 security tests covering delegation scenarios
   - ‚úÖ E2E tests: All 30 tests pass with security enabled
   - ‚úÖ Documentation: README and .env.local.example updated
   - **Impact:** CRITICAL security fix - prevents impersonation attacks in production

**Deliverable:** Production-ready multi-tenant RAG system with secure user isolation

---

### Phase 2: Quality Improvements (Next Month)
**Goal:** Match industry-standard search quality

2. **Reranking** (6 hours) üü° P1
   - Integrate cross-encoder/ms-marco-MiniLM-L-6-v2
   - Add reranking step after vector search
   - Benchmark quality improvements
   - Optional: make reranking toggleable

3. **Hybrid Search** (8 hours) üü° P1
   - Enable pg_trgm extension
   - Add tsvector column + GIN index
   - Implement weighted scoring (0.7 vector + 0.3 BM25)
   - Add keyword extraction from queries
   - Test on exact match scenarios

**Deliverable:** Best-in-class search quality

---

### Phase 3: Advanced Features (Backlog)
**Goal:** Differentiation and optimization

4. **Document Versioning** (8 hours) üü¢ P3
   - Implement soft delete + replacement tracking
   - Add version history API endpoints
   - Support rollback to previous versions

5. **Parent Document Retrieval** (10 hours) üü¢ P3
   - Add parent-child chunk relationship
   - Implement hierarchical chunking
   - Return parent context for better LLM generation

6. **Async Processing** (10 hours) üü¢ P4
   - Implement background job queue (Cloud Tasks)
   - Return 202 Accepted for uploads
   - Add job status polling endpoint
   - Webhook notifications on completion

7. **Query Analytics** (6 hours) üü¢ P4
   - Log all queries with metadata
   - Build analytics dashboard
   - Implement user feedback collection
   - Track popular queries and zero-result cases

---

## üöÄ Quick Wins (Immediate Impact)

### 1. Metadata Filtering (4 hours)
**Why First:**
- Highest impact/effort ratio
- Unblocks multi-tenancy
- Required for production SaaS
- Simple implementation (native PostgreSQL JSONB)

**Next Steps:**
1. Add metadata column to schema
2. Update QueryRequest model
3. Modify search_similar_chunks() SQL
4. Add tests
5. Update API documentation

### 2. Add Example Filters to README (30 minutes)
**Why:**
- Documents intended usage patterns
- Educates users on best practices
- Low effort, high clarity

---

## üìù Implementation Notes

### Metadata Filtering Deep Dive

**Schema Migration:**
```sql
-- Add metadata column
ALTER TABLE original_documents 
ADD COLUMN metadata JSONB DEFAULT '{}'::jsonb;

-- Create GIN index for fast filtering
CREATE INDEX idx_documents_metadata 
ON original_documents USING gin(metadata);

-- Optional: Add specific indexes for common filters
CREATE INDEX idx_documents_user_id 
ON original_documents ((metadata->>'user_id'));
```

**API Examples:**
```bash
# Upload with metadata
curl -X POST /v1/documents/upload \
  -F "file=@report.pdf" \
  -F "metadata={\"user_id\":\"user123\",\"tags\":[\"finance\",\"Q4\"],\"department\":\"accounting\",\"status\":\"approved\"}"

# Simple filter query
curl -X POST /v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "revenue analysis",
    "top_k": 5,
    "min_similarity": 0.5,
    "filters": {
      "user_id": "user123",
      "tags": {"$in": ["finance", "accounting"]}
    }
  }'

# Complex filter with AND/OR/NOT
curl -X POST /v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "contract terms",
    "filters": {
      "$and": [
        {"user_id": "user123"},
        {
          "$or": [
            {"tags": {"$all": ["legal", "reviewed"]}},
            {"department": "legal"}
          ]
        },
        {
          "$not": {
            "$or": [
              {"status": "archived"},
              {"confidentiality": "top-secret"}
            ]
          }
        },
        {"created_at": {"$gte": "2025-01-01"}}
      ]
    }
  }'

# Range queries
curl -X POST /v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "quarterly reports",
    "filters": {
      "created_at": {
        "$gte": "2025-10-01",
        "$lt": "2026-01-01"
      },
      "score": {"$gte": 80}
    }
  }'
```

**MongoDB ‚Üí PostgreSQL Mapping:**

| MongoDB Filter | PostgreSQL WHERE Clause | Example |
|----------------|-------------------------|---------|
| `{"field": "value"}` | `metadata->>'field' = 'value'` | Exact match |
| `{"field": {"$eq": "value"}}` | `metadata->>'field' = 'value'` | Explicit equality |
| `{"field": {"$ne": "value"}}` | `metadata->>'field' != 'value'` | Not equal |
| `{"field": {"$gt": 100}}` | `(metadata->>'field')::numeric > 100` | Greater than |
| `{"field": {"$gte": 100}}` | `(metadata->>'field')::numeric >= 100` | Greater or equal |
| `{"field": {"$lt": 100}}` | `(metadata->>'field')::numeric < 100` | Less than |
| `{"field": {"$lte": 100}}` | `(metadata->>'field')::numeric <= 100` | Less or equal |
| `{"tags": {"$in": ["a","b"]}}` | `metadata->'tags' ?| array['a','b']` | Array contains ANY |
| `{"tags": {"$all": ["a","b"]}}` | `metadata->'tags' ?& array['a','b']` | Array contains ALL |
| `{"tags": {"$nin": ["a","b"]}}` | `NOT (metadata->'tags' ?| array['a','b'])` | Array contains NONE |
| `{"field": {"$exists": true}}` | `metadata ? 'field'` | Key exists |
| `{"field": {"$exists": false}}` | `NOT (metadata ? 'field')` | Key doesn't exist |
| `{"$and": [A, B]}` | `(A_clause) AND (B_clause)` | Logical AND |
| `{"$or": [A, B]}` | `(A_clause) OR (B_clause)` | Logical OR |
| `{"$not": A}` | `NOT (A_clause)` | Logical NOT |

---

## üéì Learning Resources

**Metadata Filtering:**
- PostgreSQL JSONB: https://www.postgresql.org/docs/current/datatype-json.html
- GIN Indexes: https://www.postgresql.org/docs/current/gin-intro.html

**Reranking:**
- Cross-Encoders: https://www.sbert.net/examples/applications/cross-encoder/README.html
- MS MARCO: https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2

**Hybrid Search:**
- BM25: https://en.wikipedia.org/wiki/Okapi_BM25
- PostgreSQL Full-Text Search: https://www.postgresql.org/docs/current/textsearch.html

---

## üîÑ Version History

**v0.2.0 (Current - Dec 11, 2025):**
- ‚úÖ Inline unit test fixtures
- ‚úÖ Similarity threshold filtering (min_similarity)
- ‚úÖ 74 comprehensive tests (49 unit, 20 e2e, 5 integration)
- ‚úÖ Enhanced Swagger documentation

**v0.1.0 (Initial Release):**
- ‚úÖ Core RAG pipeline (upload, chunk, embed, search)
- ‚úÖ Multi-format support (17 formats)
- ‚úÖ Hybrid storage (PostgreSQL + GCS)
- ‚úÖ SHA256 deduplication
- ‚úÖ Cloud Run deployment

**v0.3.0 (Planned - Next 2 Weeks):**
- üîÑ Metadata filtering + multi-tenancy

---

## üìû Next Steps & Priorities

### üéØ Immediate Next Action (Choose One):

**Option A: Hybrid Search Phase 3 - BM25 Query Integration** (Technical Completion)
- **Effort:** 2-3 hours
- **Impact:** Complete hybrid search feature (vector + BM25 + RRF fusion)
- **Value:** Better retrieval quality, keyword+semantic search combined
- **Tasks:**
  1. Load BM25 index from GCS in `/v1/query` endpoint
  2. Implement BM25 scoring (TF-IDF with stemming)
  3. RRF fusion (vector + BM25 scores)
  4. E2E tests for hybrid queries
  5. Documentation update

**Option B: Metadata Filtering** (Product/SaaS Critical)
- **Effort:** 4 hours
- **Impact:** Enable multi-tenancy, production SaaS deployment
- **Value:** User isolation, document categorization, time-based filtering
- **Tasks:**
  1. Add `metadata JSONB` column to PostgreSQL
  2. Implement MongoDB-style filter parser
  3. Update `/v1/query` and `/v1/upload` endpoints
  4. E2E tests for multi-tenant isolation
  5. Documentation update

**Option C: BigQuery Billing Analytics** (Cost Optimization)
- **Status:** Infrastructure ready, waiting for data (Dec 19-20)
- **Next:** Analyze costs when data arrives, optimize expensive operations
- **Tasks:**
  1. Query billing data (scripts/query_billing.py)
  2. Identify cost drivers (Gemini API, embeddings, storage)
  3. Create cost dashboard queries
  4. Optimize if needed

### üóìÔ∏è Recommended Sequence:

1. **Today (Dec 19):** Wait for billing data ‚Üí analyze costs
2. **Next session:** Choose Phase 3 (technical) OR Metadata Filtering (product)
3. **Future:** Complete whichever wasn't chosen in step 2

---

## üìù Implementation Commands

**To implement Hybrid Search Phase 3:**
```
"Implement Hybrid Search Phase 3 from ROADMAP.md - BM25 query integration with RRF fusion"
```

**To implement Metadata Filtering:**
```
"Implement metadata filtering from ROADMAP.md - MongoDB-style filters for multi-tenancy"
```

**To analyze billing data:**
```
"Analyze BigQuery billing data - identify cost drivers and optimize"
```

---

**Status:** Ready for Phase 1 implementation
**Contact:** Start new conversation with "Continue from ROADMAP.md Phase 1"
